{
 "cells": [
  {
   "source": [
    "# <ins>Analysis on the Potential of Life on Exoplanets</ins>\n",
    "\n",
    "## By: Ethan Barr and Tim Freerksen"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## <ins>Introduction</ins>\n",
    "\n",
    "Is there life in space? This has been a question for many years with no real evidence to back up the claim that there is. Our goal in this project is to take the exoplanets already discovered and see what the probability of life on these planets real is and hope that a good amount of the exoplanets that we discovered so far fit well into the criteria of haveing the ability to hold life.\n",
    "\n",
    "Throughout this tutorial, we will try to see how many of the exoplanets we have discovered so far the right conditions in order to harbor life and then we will see what the probability is that a future exoplanet will end up holding life."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### <ins>Required Tools</ins>\n",
    "\n",
    "The following libraries used for the project:\n",
    "\n",
    "    1. pandas\n",
    "    2. \n",
    "\n",
    "If having issues with python 3+ or panda, we recommend referring to these following websites for more information:\n",
    "\n",
    "    1. https://docs.python.org/3/\n",
    "    2. https://pandas.pydata.org/pandas-docs/stable/install.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### <ins>1. Data Collection</ins>\n",
    "\n",
    "This is the first part of the data life cycle. In this part we will go through various websites to try and find data that both matches our topic at hand as well as gives enough information so that we can perform an analysis later on. \n",
    "\n",
    "For an Exoplanet Database we found that https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=PS gave the best and most information. In order to retrieve this data we first converted the online database into a csv file in which we could then read and manipulate.\n",
    "\n",
    "The following tools were used for the data collection:\n",
    "\n",
    "    1. panda"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # used in order to read the csv file and convert it successfully into a datafram"
   ]
  },
  {
   "source": [
    "Since the exoplanetarchive website was nice enough to allow the downloading of the database into a csv file, there was not a lot of steps to fully access the entire database. It was sufficient to first download the database in a csv format and then add it as one of the files with this project. We could then easily access this file by performing a pandas read_csv which allowed for the entire csv file to be converted into a flexibile and readable DataFrame that we could use.\n",
    "\n",
    "A <ins>DataFrame</ins> is a table that has rows and columns that correlate to certain pieces of data. Using DataFrames allows for better use of more pandas functions which help to manipulate this data much more flexibily. If interested in learning more about DataFrames then check out the pandas documentation of it at https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html\n",
    "\n",
    "The only issue that the csv had when we first read it was that the data provided had its only numbering associated with each row. To combact this we decided to stick with how the original data numbered itself and assigned that row to be the row number titled, loc_rowid.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            pl_name hostname  default_flag  sy_snum  sy_pnum  discoverymethod  \\\nloc_rowid                                                                       \n1          11 Com b   11 Com             0        2        1  Radial Velocity   \n2          11 Com b   11 Com             1        2        1  Radial Velocity   \n3          11 UMi b   11 UMi             0        1        1  Radial Velocity   \n4          11 UMi b   11 UMi             0        1        1  Radial Velocity   \n5          11 UMi b   11 UMi             1        1        1  Radial Velocity   \n\n           disc_year                           disc_facility  \\\nloc_rowid                                                      \n1               2007                        Xinglong Station   \n2               2007                        Xinglong Station   \n3               2009  Thueringer Landessternwarte Tautenburg   \n4               2009  Thueringer Landessternwarte Tautenburg   \n5               2009  Thueringer Landessternwarte Tautenburg   \n\n                       soltype  pl_controv_flag  ... sy_vmagerr2  sy_kmag  \\\nloc_rowid                                        ...                        \n1          Published Confirmed                0  ...      -0.023    2.282   \n2          Published Confirmed                0  ...      -0.023    2.282   \n3          Published Confirmed                0  ...      -0.005    1.939   \n4          Published Confirmed                0  ...      -0.005    1.939   \n5          Published Confirmed                0  ...      -0.005    1.939   \n\n           sy_kmagerr1  sy_kmagerr2  sy_gaiamag  sy_gaiamagerr1  \\\nloc_rowid                                                         \n1                0.346       -0.346     4.44038        0.003848   \n2                0.346       -0.346     4.44038        0.003848   \n3                0.270       -0.270     4.56216        0.003903   \n4                0.270       -0.270     4.56216        0.003903   \n5                0.270       -0.270     4.56216        0.003903   \n\n           sy_gaiamagerr2            rowupdate  pl_pubdate  releasedate  \nloc_rowid                                                                \n1               -0.003848           2014-07-23     2011-08   2014-07-23  \n2               -0.003848           2014-05-14     2008-01   2014-05-14  \n3               -0.003903  2018-04-25 14:08:01     2009-10   2014-05-14  \n4               -0.003903  2018-04-25 14:08:01     2011-08   2014-07-23  \n5               -0.003903  2018-09-04 16:14:36     2017-03   2018-09-06  \n\n[5 rows x 91 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('PS.csv')\n",
    "data.set_index('loc_rowid', inplace=True)\n",
    "print(data.head())"
   ]
  },
  {
   "source": [
    "### <ins>2. Data Processing</ins>\n",
    "\n",
    "After you successfully retrieve the data that you are looking for and have it in some sort of dataframe so that you can manipulate it then you move onto this next step. Within this step we want to try and tidy up the data that we just read in. This is an important step because of the fact that it will allow the data to be read and understood with much more fluidity. In our case we would be altering the structure of the DataFrame through the process of tidying data and / or data wrangling.\n",
    "\n",
    "You can learn more about:\n",
    "\n",
    "    1. tidying data: https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html\n",
    "    2. data wrangling: https://www.elderresearch.com/blog/what-is-data-wrangling-and-why-does-it-take-so-long/#:~:text=Data%20wrangling%20is%20the%20process,20%25%20for%20exploration%20and%20modeling.\n",
    "\n",
    "We will now go through the steps of tiding up our DataFrame so that any extra information is scrap the columns that are repeated but with slightly different values due to the units that they are being shown in. We also want to convert the units that a few columns are using in order to allow for calculations to be performed a lot quickly and with ease."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}